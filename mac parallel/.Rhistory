x <- exp(x)/(exp(x)+1)
return(x)
}
mytrue <- function(a_1s = 1, a_2s = 1){
#visit 1;
w1sim <- rbinom(samplesize, 1, prob = 0.5) #50-50 male and female;
w2sim <- rnorm(samplesize, mean = 12, sd = 4) #age;
L1_1sim <- rbinom(samplesize, 1, prob = expit(-1 + 0.01*w1sim + 0.01*w2sim)) #a age related baseline binary clinical variable;
L2_1sim <- rnorm(samplesize, mean = (0.01*w1sim + 0.01*w2sim), sd = 1) #a age & sex related baseline continuous clinical variable;
#Visit 2, simulate all potential variables;
L1_2sim <- rbinom(samplesize, 1, expit(-1 + 0.01*w1sim + 0.01*w2sim + 0.2*L1_1sim - 0.2*a_1s))
L2_2sim <- rnorm(samplesize, mean = (L2_1sim - 0.01*w1sim + 0.01*w2sim - 0.2*a_1s), sd = 1)
#Visit 3, simulate potential outcomes;
truemean = (1 - 1*a_1s - 2*a_2s + 0.01*a_1s*a_2s - 0.1*w1sim + 0.01*w2sim + 0.1*L1_2sim + 0.1*L2_2sim)
return(mean(truemean))
}
# ###
# #
# ###
#
# Download package tarball from CRAN archive
# url <- "https://cran.r-project.org/src/contrib/Archive/ipw/ipw_1.0-1.tar.gz"
# # url <- "http://cran.r-project.org/src/contrib/Archive/RecordLinkage/RecordLinkage_0.4-1.tar.gz"
# pkgFile <- "ipw_1.0-1.tar.gz"
# download.file(url = url, destfile = pkgFile)
#
# # Expand the zip file using whatever system functions are preferred
#
# # look at the DESCRIPTION file in the expanded package directory
#
# # Install dependencies list in the DESCRIPTION file
#
# install.packages(c("geepack", "ipred", "evd"))
#
# # Install package
# install.packages(pkgs=pkgFile, type="source", repos=NULL)
#
# # Delete package tarball
# unlink(pkgFile)
options(warn=-1)
#parallel;
library(parallel)
library(foreach)
library(doParallel)
library(tidyverse)
library(survey)
library(arm)
library(ltmle)
library(ipw) #MSM;
library(gfoRmula) #g-computation;
library(gtsummary)
library(SuperLearner)
library(WeightIt)
library(doMC)
detectCores()
registerDoMC(detectCores() - 3)
S  <- Sys.time()
#pre-define function;
# ncores<-4
mysim.cont <- function(outfile, from=1, to=4, ntot=1000, samplesize=10000) {
# Simulation setup;
# ntot=1000;
# samplesize=10000;
# from = 1;
# to = 3;
#  library(doParallel)
# registerDoParallel(ncores)
expit <- function(x){
x <- exp(x)/(exp(x)+1)
return(x)
}
mytrue <- function(a_1s = 1, a_2s = 1){
#visit 1;
w1sim <- rbinom(samplesize, 1, prob = 0.5) #50-50 male and female;
w2sim <- rnorm(samplesize, mean = 12, sd = 4) #age;
L1_1sim <- rbinom(samplesize, 1, prob = expit(-1 + 0.01*w1sim + 0.01*w2sim)) #a age related baseline binary clinical variable;
L2_1sim <- rnorm(samplesize, mean = (0.01*w1sim + 0.01*w2sim), sd = 1) #a age & sex related baseline continuous clinical variable;
#Visit 2, simulate all potential variables;
L1_2sim <- rbinom(samplesize, 1, expit(-1 + 0.01*w1sim + 0.01*w2sim + 0.2*L1_1sim - 0.2*a_1s))
L2_2sim <- rnorm(samplesize, mean = (L2_1sim - 0.01*w1sim + 0.01*w2sim - 0.2*a_1s), sd = 1)
#Visit 3, simulate potential outcomes;
truemean = (1 - 1*a_1s - 2*a_2s + 0.01*a_1s*a_2s - 0.1*w1sim + 0.01*w2sim + 0.1*L1_2sim + 0.1*L2_2sim)
return(mean(truemean))
}
results_run<-foreach(i=from:to, .combine=rbind,.errorhandling = "stop") %dopar% {
# true value;
# each method and each setting, est, se(est), low 95%CI, upper 95%CI;
# data generation;
set.seed(i+123)
results.it <- matrix(NA, 1, 21)
# Visit 1
w1 <- rbinom(ntot, 1, prob = 0.5) #50-50 male and female (reference);
w2 <- rnorm(ntot, mean = 12, sd = 4) #age;
L1_1 <- rbinom(ntot, 1, prob = expit(-1 + 0.01*w1 + 0.01*w2)) #a age & sex related baseline binary clinical variable;
L2_1 <- rnorm(ntot, mean = (0.01*w1 + 0.01*w2), sd = 1) #a age & sex related baseline continuous clinical variable;
a_1 <- rbinom(ntot, 1, expit(-1 - 0.01*w1 + 0.01*w2 - 0.1*L1_1 + 0.1*L2_1))
# observational data;
L1_2 <- rbinom(ntot, 1, expit(-1 + 0.01*w1 + 0.01*w2 + 0.2*L1_1 - 0.2*a_1))
L2_2 <- rnorm(ntot, mean = (L2_1 - 0.01*w1 + 0.01*w2 - 0.2*a_1), sd = 1)
a_2 <- rbinom(ntot, 1, expit(-1 - 0.01*w1 + 0.01*w2 - 0.1*L1_2 + 0.1*L2_2 + a_1))
# end-of-study outcome;
y <- rnorm(ntot, mean = (1 - 1*a_1 - 2*a_2 + 0.01*a_1*a_2 - 0.2*w1 + 0.1*w2 + 0.4*L1_2 + 0.2*L2_2) , sd = 1)
# saving final data
dat1 <- data.frame(w1, w2, L1_1, L2_1, a_1, L1_2, L2_2, a_2, y)
results.it[1,1] <- mytrue(a_1s = 1, a_2s = 1) - mytrue(a_1s = 0, a_2s = 0)
# gformula package
dat1_new <- dat1 %>%
mutate(id = rep(1:1000)) %>%
pivot_longer(cols = -c(w1,w2,y,id),
names_to = c("variable","visit"),
names_sep = "_",
values_to = "value") %>%
pivot_wider(names_from = variable, values_from = value) %>%
mutate(time = case_when(visit == 1 ~ 0,
visit == 2 ~ 1))
dat1_new$y[dat1_new$visit == 1] <- NA
id <- 'id'
time_name <- 'time'
# create one to for the package
covnames <- c("L1", "L2", "a")
outcome_name <- 'y'
covtypes <- c('binary', 'normal', 'binary')
histories <- c(lagged)
histvars <- list(c('a', 'L1', 'L2'))
covparams <- list(covmodels = c(L1 ~ w1 + w2 + lag1_L1 + lag1_a,
L2 ~ w1 + w2 + lag1_L2 + lag1_a,
a ~ w1 + w2 + lag1_L1 + L1 + lag1_L2 + L2 + lag1_a))
ymodel <- y ~ lag1_a + a + lag1_a*a + w1 + w2 + L1 + L2 + lag1_L1 + lag1_L2
intvars <- list('a', 'a')
interventions <- list(list(c(static, rep(0, 2))),
list(c(static, rep(1, 2))))
int_descript <- c('Never treat', 'Always treat')
gform_cont_eof <- gformula_continuous_eof(
obs_data = dat1_new,
id = id,
time_name = time_name,
covnames =covnames,
outcome_name = outcome_name,
covtypes = c("binary", "normal", "binary"),
covparams = covparams,  ymodel = ymodel,
intvars = intvars, interventions = interventions,
int_descript = int_descript,
ref_int = 1,
histories = c(lagged), histvars = list(c('a',"L1","L2")),
basecovs = c("w1","w2"),
# boot_diag = TRUE,
nsimul = 1000,
nsamples = 1000, parallel = TRUE, ncores = 6,
seed = 123)
results.it[1, 2:5] <- unlist(gform_cont_eof$result[3,12:15])
# ltmle packages;
# ltmle without superlearner + kitchen sink gform + Qform (kitchen sink);
tmle_model <- ltmle(dat1,
Anodes = c ("a_1","a_2") ,
Lnodes = c ("L1_1", "L2_1", "L1_2", "L2_2"),
Ynodes = c("y"),
survivalOutcome =FALSE,
Qform = c( L1_2 = "Q.kplus1 ~ w1 + w2 + L1_1 + a_1",
y = "Q.kplus1 ~ w1 + w2 + L1_2 + L2_2 + a_1 + a_2 + a_1*a_2"),
gform = c("a_1 ~ w1 + w2 + L1_1 + L2_1",
"a_2 ~ w1 + w2 + L1_1 + L2_1 + L1_2 + L2_2 + a_1"),
abar = list(c(1,1), c(0,0)),
estimate.time = FALSE)
out_tmle <- summary(tmle_model, estimator="tmle")
results.it[1,6]<- out_tmle$effect.measures$ATE$estimate
results.it[1,7]<- out_tmle$effect.measures$ATE$std.dev
results.it[1,8:9] <- out_tmle$effect.measures$ATE$CI
# ltmle with superlearner + kitchen sink gform + Qform;
tmle_model_s <- ltmle(dat1,
Anodes = c ("a_1","a_2") ,
Lnodes = c ("L1_1", "L2_1", "L1_2", "L2_2"),
Ynodes = c("y"),
survivalOutcome =FALSE,
Qform = c( L1_2 = "Q.kplus1 ~ w1 + w2 + L1_1 + a_1",
y = "Q.kplus1 ~ w1 + w2 + L1_2 + L2_2 + a_1 + a_2 + a_1*a_2"),
gform = c("a_1 ~ w1 + w2 + L1_1 + L2_1",
"a_2 ~ w1 + w2 + L1_1 + L2_1 + L1_2 + L2_2 + a_1"),
SL.library = "default", #with superlearner;
abar = list(c(1,1), c(0,0)),
estimate.time = FALSE)
out_tmle_s<-summary(tmle_model_s, estimator="tmle")
results.it[1,10]<- out_tmle_s$effect.measures$ATE$estimate
results.it[1,11]<- out_tmle_s$effect.measures$ATE$std.dev
results.it[1,12:13] <- out_tmle_s$effect.measures$ATE$CI
# ipw package
# creating long format data;
dat1 <- dat1 %>%
mutate(id = rep(1:1000),
cum_a = a_1 + a_2)
# model using ipwpoint
weights_v1 <- ipwpoint(
exposure = a_1,
family = "gaussian",
numerator = ~ 1,
denominator = ~ w1 + w2 + L1_1 + L2_1,
data = as.data.frame(dat1))
weights_v2 <- ipwpoint(
exposure = a_2,
family = "gaussian",
numerator = ~ a_1,
denominator = ~ w1 + w2 + L1_1 + L2_1 + L1_2 + L2_2 + a_1,
data = as.data.frame(dat1))
w <- weights_v1$ipw.weights * weights_v2$ipw.weights
cont_design <- svydesign(id=~1, weights = ~ w, data = dat1)
cont_mod <- svyglm(y ~ as.factor(cum_a), design = cont_design)
results.it[1,14:17] <- cbind(summary(cont_mod)$coef[,1:2], confint(cont_mod))[3,]
# weightit package
Wmsm.out <- weightitMSM(list(a_1 ~ w1 + w2 + L1_1 + L2_1,
a_2 ~ w1 + w2 + L1_1 + L2_1 + L1_2 + L2_2 + a_1),
data = dat1, method = "ps",
stabilize = TRUE)
# estimate treatment effect
d.w.msm <- svydesign(~1, weights = Wmsm.out$weights,
data = dat1)
cum.fit <- svyglm(y ~ as.factor(cum_a), design = d.w.msm)
results.it[1,18:21] <- cbind(summary(cum.fit)$coef[,1:2], confint(cum.fit))[3,]
cbind(i,results.it)
}
# outfile <-"textcontsim"
write.table(results_run, file = paste0(outfile,".txt"), row.names = FALSE,col.names = FALSE)
}
suppressWarnings(mysim.cont(paste0("Oct25","cont","run"), from=1, to=2, ntot=1000, samplesize=10000))
Sys.time() - S
from=1, to=4, ntot=1000, samplesize=10000
from=1; to=4; ntot=1000; samplesize=10000
results_run<-foreach(i=from:to, .combine=rbind,.errorhandling = "stop") %dopar% {
# true value;
# each method and each setting, est, se(est), low 95%CI, upper 95%CI;
# data generation;
set.seed(i+123)
results.it <- matrix(NA, 1, 21)
# Visit 1
w1 <- rbinom(ntot, 1, prob = 0.5) #50-50 male and female (reference);
w2 <- rnorm(ntot, mean = 12, sd = 4) #age;
L1_1 <- rbinom(ntot, 1, prob = expit(-1 + 0.01*w1 + 0.01*w2)) #a age & sex related baseline binary clinical variable;
L2_1 <- rnorm(ntot, mean = (0.01*w1 + 0.01*w2), sd = 1) #a age & sex related baseline continuous clinical variable;
a_1 <- rbinom(ntot, 1, expit(-1 - 0.01*w1 + 0.01*w2 - 0.1*L1_1 + 0.1*L2_1))
# observational data;
L1_2 <- rbinom(ntot, 1, expit(-1 + 0.01*w1 + 0.01*w2 + 0.2*L1_1 - 0.2*a_1))
L2_2 <- rnorm(ntot, mean = (L2_1 - 0.01*w1 + 0.01*w2 - 0.2*a_1), sd = 1)
a_2 <- rbinom(ntot, 1, expit(-1 - 0.01*w1 + 0.01*w2 - 0.1*L1_2 + 0.1*L2_2 + a_1))
# end-of-study outcome;
y <- rnorm(ntot, mean = (1 - 1*a_1 - 2*a_2 + 0.01*a_1*a_2 - 0.2*w1 + 0.1*w2 + 0.4*L1_2 + 0.2*L2_2) , sd = 1)
# saving final data
dat1 <- data.frame(w1, w2, L1_1, L2_1, a_1, L1_2, L2_2, a_2, y)
results.it[1,1] <- mytrue(a_1s = 1, a_2s = 1) - mytrue(a_1s = 0, a_2s = 0)
# gformula package
dat1_new <- dat1 %>%
mutate(id = rep(1:1000)) %>%
pivot_longer(cols = -c(w1,w2,y,id),
names_to = c("variable","visit"),
names_sep = "_",
values_to = "value") %>%
pivot_wider(names_from = variable, values_from = value) %>%
mutate(time = case_when(visit == 1 ~ 0,
visit == 2 ~ 1))
dat1_new$y[dat1_new$visit == 1] <- NA
id <- 'id'
time_name <- 'time'
# create one to for the package
covnames <- c("L1", "L2", "a")
outcome_name <- 'y'
covtypes <- c('binary', 'normal', 'binary')
histories <- c(lagged)
histvars <- list(c('a', 'L1', 'L2'))
covparams <- list(covmodels = c(L1 ~ w1 + w2 + lag1_L1 + lag1_a,
L2 ~ w1 + w2 + lag1_L2 + lag1_a,
a ~ w1 + w2 + lag1_L1 + L1 + lag1_L2 + L2 + lag1_a))
ymodel <- y ~ lag1_a + a + lag1_a*a + w1 + w2 + L1 + L2 + lag1_L1 + lag1_L2
intvars <- list('a', 'a')
interventions <- list(list(c(static, rep(0, 2))),
list(c(static, rep(1, 2))))
int_descript <- c('Never treat', 'Always treat')
gform_cont_eof <- gformula_continuous_eof(
obs_data = dat1_new,
id = id,
time_name = time_name,
covnames =covnames,
outcome_name = outcome_name,
covtypes = c("binary", "normal", "binary"),
covparams = covparams,  ymodel = ymodel,
intvars = intvars, interventions = interventions,
int_descript = int_descript,
ref_int = 1,
histories = c(lagged), histvars = list(c('a',"L1","L2")),
basecovs = c("w1","w2"),
# boot_diag = TRUE,
nsimul = 1000,
nsamples = 1000, parallel = TRUE, ncores = 6,
seed = 123)
results.it[1, 2:5] <- unlist(gform_cont_eof$result[3,12:15])
# ltmle packages;
# ltmle without superlearner + kitchen sink gform + Qform (kitchen sink);
tmle_model <- ltmle(dat1,
Anodes = c ("a_1","a_2") ,
Lnodes = c ("L1_1", "L2_1", "L1_2", "L2_2"),
Ynodes = c("y"),
survivalOutcome =FALSE,
Qform = c( L1_2 = "Q.kplus1 ~ w1 + w2 + L1_1 + a_1",
y = "Q.kplus1 ~ w1 + w2 + L1_2 + L2_2 + a_1 + a_2 + a_1*a_2"),
gform = c("a_1 ~ w1 + w2 + L1_1 + L2_1",
"a_2 ~ w1 + w2 + L1_1 + L2_1 + L1_2 + L2_2 + a_1"),
abar = list(c(1,1), c(0,0)),
estimate.time = FALSE)
out_tmle <- summary(tmle_model, estimator="tmle")
results.it[1,6]<- out_tmle$effect.measures$ATE$estimate
results.it[1,7]<- out_tmle$effect.measures$ATE$std.dev
results.it[1,8:9] <- out_tmle$effect.measures$ATE$CI
# ltmle with superlearner + kitchen sink gform + Qform;
tmle_model_s <- ltmle(dat1,
Anodes = c ("a_1","a_2") ,
Lnodes = c ("L1_1", "L2_1", "L1_2", "L2_2"),
Ynodes = c("y"),
survivalOutcome =FALSE,
Qform = c( L1_2 = "Q.kplus1 ~ w1 + w2 + L1_1 + a_1",
y = "Q.kplus1 ~ w1 + w2 + L1_2 + L2_2 + a_1 + a_2 + a_1*a_2"),
gform = c("a_1 ~ w1 + w2 + L1_1 + L2_1",
"a_2 ~ w1 + w2 + L1_1 + L2_1 + L1_2 + L2_2 + a_1"),
SL.library = "default", #with superlearner;
abar = list(c(1,1), c(0,0)),
estimate.time = FALSE)
out_tmle_s<-summary(tmle_model_s, estimator="tmle")
results.it[1,10]<- out_tmle_s$effect.measures$ATE$estimate
results.it[1,11]<- out_tmle_s$effect.measures$ATE$std.dev
results.it[1,12:13] <- out_tmle_s$effect.measures$ATE$CI
# ipw package
# creating long format data;
dat1 <- dat1 %>%
mutate(id = rep(1:1000),
cum_a = a_1 + a_2)
# model using ipwpoint
weights_v1 <- ipwpoint(
exposure = a_1,
family = "gaussian",
numerator = ~ 1,
denominator = ~ w1 + w2 + L1_1 + L2_1,
data = as.data.frame(dat1))
weights_v2 <- ipwpoint(
exposure = a_2,
family = "gaussian",
numerator = ~ a_1,
denominator = ~ w1 + w2 + L1_1 + L2_1 + L1_2 + L2_2 + a_1,
data = as.data.frame(dat1))
w <- weights_v1$ipw.weights * weights_v2$ipw.weights
cont_design <- svydesign(id=~1, weights = ~ w, data = dat1)
cont_mod <- svyglm(y ~ as.factor(cum_a), design = cont_design)
results.it[1,14:17] <- cbind(summary(cont_mod)$coef[,1:2], confint(cont_mod))[3,]
# weightit package
Wmsm.out <- weightitMSM(list(a_1 ~ w1 + w2 + L1_1 + L2_1,
a_2 ~ w1 + w2 + L1_1 + L2_1 + L1_2 + L2_2 + a_1),
data = dat1, method = "ps",
stabilize = TRUE)
# estimate treatment effect
d.w.msm <- svydesign(~1, weights = Wmsm.out$weights,
data = dat1)
cum.fit <- svyglm(y ~ as.factor(cum_a), design = d.w.msm)
results.it[1,18:21] <- cbind(summary(cum.fit)$coef[,1:2], confint(cum.fit))[3,]
cbind(i,results.it)
}
detectCores()
registerDoMC(detectCores() - 4)
S  <- Sys.time()
#### Generate a simple dataset ##
### Mars with interaction ##
### MARS VIM ###
#### VIM for BIG data  ####
#R CMD BATCH myfile.R
# nohup R CMD BATCH file.R file2.Rout &
# tail -f file2.Rout
rm(list=ls())
gc()
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/Thesis Stuff/Draft of paper 1/Latest results April 22/Test Codes")
#### Generate a simple dataset ##
### Mars with interaction ##
### MARS VIM ###
#### VIM for BIG data  ####
#R CMD BATCH myfile.R
# nohup R CMD BATCH file.R file2.Rout &
# tail -f file2.Rout
rm(list=ls())
gc()
# setwd("~/Library/Mobile Documents/com~apple~CloudDocs/Thesis Stuff/Draft of paper 1/Latest results April 22/Test Codes")
## load the packages
library(tidyverse)
library(grid)
library(lattice)
library(BSDA)
library(boot)
#library(mvtnorm)
library(MASS)
library(mvnfast)
library(gam)
library(xgboost)#(gbm)
library(ranger)
library(glmnet)
library(parallel)
library(doMC)
detectCores()
registerDoMC(detectCores() - 3)
S  <- Sys.time()
bet <- c(1,2,0.5,0)
gendata <- function(n, num.p, t.var, bet = bet){
zmat <- matrix(runif(n * num.p, -1, 1), ncol = num.p)
X <- zmat[, 1:t.var] %*% bet + rnorm(n, 0, 5)
C1 <- t(rmultinom(n, size = 1, prob = rep(1/3, 3))); C1[,1] <- 0
Ya <- 1 + 1*C1[,2] + 2*C1[,3] + 3 * X + 4 * zmat[,1] - 3*zmat[,2] + 2 * zmat[,3] - 1 * zmat[,4]
eps <- rnorm(n, 0, 1)
Y <- Ya + eps
cat1 <- rep(0,n)
cat1 <- ifelse(C1[,2]==1, 1, ifelse(C1[,3]==1, 2, 0))
dat <- data.frame(cbind(X, zmat, cat1, Y, Ya))
colnames(dat) <- c("X", paste0("Z", 1:num.p), "cat1", "Y", "Ya" )
dat$cat1 <- as.factor(dat$cat1)
return(dat)
}
### Generate the data ##
# Calculate the true VIMs ##
vx <- 2 *(25 + sum(bet^2)/3) * 3^2
vz1 <- 2 * 4^2 * (1/3); vz2 <- 2 * 3^2 * 1/3 ; vz3 <- 2 * 2^2 * 1/3 ; vz4 <- 2 * 1^2 * 1/3
bet.cat <- c(1,2)
cov.cat.mat <- matrix(c(1/3 * 2/3, -(1/3)^2,  -(1/3)^2,
1/3 * 2/3), ncol = 2)
vcat <- 2 * t(bet.cat ) %*% cov.cat.mat %*% bet.cat
VIM.T <- c(vx, vz1, vz2, vz3, vz4,0,0, vcat)
## Simulate the observations ##
ntrain <- c(100, 200, 500, 1000, 5000, 10000)
n.depth <- c(rep(1,4), rep(2,2)) #c(rep(1,3), 3, 6, 7)
num.tree.boost <- c(rep(100, 4), 100, 100)
num.tree.RF <- c(rep(2000, 6)) #, 500, 500)
VIM.comp <- foreach(ii = 1:100, .combine = rbind, .errorhandling = "stop") %dopar% {
VIM.all <- matrix(NA, ncol = 12, nrow = length(VIM.T)*length(ntrain))
set.seed(100*ii)
for(j in 1:length(ntrain)){
t.var <- 4; n <- ntrain[j]; n.test <- ceiling(n * 1/2)
num.p <- 10
#set.seed(100)
dat.train <- gendata(n = n, num.p = num.p, t.var = t.var, bet = bet)
dat.test <- gendata(n = n.test, num.p = num.p, t.var = t.var, bet = bet)
Xb <- rnorm(n = n.test, mean = 0, sd = sqrt(1 + sum(bet^2)/3))
zmat <- matrix(runif(n.test * num.p, -1, 1), ncol = num.p)
catb <- sample(c(0,1,2), n.test, prob = rep(1/3,3), replace = T)
## Actual e_orig from the test set ##
e_orig <- mean((dat.test$Y - dat.test$Ya)^2)
col.rm <- which(colnames(dat.train) %in% "Ya")
colY <- which(colnames(dat.train) %in% "Y")
## Linear Model
lm.mod <- lm(Y ~ ., data = dat.train[, -col.rm])
### Linear Model ##
lm.orig <- mean((dat.test$Y - predict(lm.mod, newdata = dat.test[, -col.rm]))^2)
## Random Forest ##
rf.fit <-  ranger(dat.train$Y ~ ., data=dat.train[, -col.rm],
num.trees = num.tree.RF[j], mtry = min(num.p, num.p - 10) )
RF.orig <- mean( (dat.test$Y -  predict(rf.fit, data = dat.test[, -col.rm],
type = "response", num.trees = num.tree.RF[j], num.threads = 5)$predictions )^2 )
## XGboost ##
dtrain <- sparse.model.matrix(Y ~ ., data = dat.train[, -col.rm])[,-colY]
dtest <- sparse.model.matrix(Y ~ ., data = dat.test[, -col.rm])[,-colY]
boost.org.train <- xgboost(params = list(eta = 0.3, max.depth = n.depth[j], subsample=0.5), data = dtrain, booster = "gbtree",
nthread = 3, nrounds = num.tree.boost[j], objective = "reg:squarederror",
verbose = 0, label = dat.train$Y)
# boost.org.train <- xgboost(data = dtrain, booster = "gblinear",
#                            nthread = 3, nrounds = num.tree.boost[j], objective = "reg:squarederror",
#                            verbose = 0, label = dat.train$Y)
boost.orig <- mean( (dat.test$Y -  predict(boost.org.train, newdata = dtest ) )^2 )
### GAM ##
fit.gam <- mgcv::gam(Y ~ s(X, bs = "cr") + s(Z1, bs = "cr") + s(Z2, bs = "cr") +
s(Z3, bs = "cr") + s(Z4, bs = "cr") + cat1,
data = dat.train[,-col.rm], family = "gaussian")
gam.orig <- mean( (dat.test$Y -  predict(fit.gam, newdata = dat.test, interval = "none") )^2 )
vars <- which(colnames(dat.train) %in% c("X", paste0("Z", 1:6), "cat1") )
lm.switch <- RF.switch <- boost.switch <- gam.switch <- vector()
for(i in 1:length(vars)){
#  print(vars[i])
dat.F <- dat.test
dat.F[, vars[i]] <- sample(dat.test[,vars[i]])
dtest.F <- sparse.model.matrix(Y ~ ., data = dat.F[, -col.rm])[,-colY]
lm.switch[i] <- mean((dat.test$Y - predict(lm.mod, newdata = dat.F[, -col.rm]))^2)
RF.switch[i] <- mean( (dat.test$Y -  predict(rf.fit, data = dat.F[, -col.rm],
type = "response", num.trees = num.tree.RF[j], num.threads = 5)$predictions )^2 )
boost.switch[i] <- mean( (dat.test$Y -  predict(boost.org.train, newdata = dtest.F ) )^2 )
gam.switch[i] <- mean( (dat.test$Y -  predict(fit.gam, newdata = dat.F, interval = "none") )^2 )
}
lm.VIM <- lm.switch - lm.orig
boost.VIM <- boost.switch - boost.orig
RF.VIM <- RF.switch - RF.orig
gam.VIM <- gam.switch - gam.orig
VIMs <- cbind(ii, ntrain[j], e_orig, VIM.T, lm.orig, lm.VIM,
boost.orig, boost.VIM, RF.orig, RF.VIM, gam.orig, gam.VIM)
k <- seq(1, length(VIM.T)*length(ntrain), by = length(VIM.T))
VIM.all[k[j]:(k[j] + (length(VIM.T) - 1)),] <- VIMs
}
Final <- VIM.all
}
VIM.comp <- as.data.frame(VIM.comp)
colnames(VIM.comp) <- c("Sim", "ntrain", "e_orig", "VIM.T", "LM.orig", "LM.VIM", "boost.orig",
"boost.VIM", "RF.orig", "RF.VIM", "GAM.orig", "GAM.VIM")
VIM.comp$Var <- rep(1:8, nrow(VIM.comp)/8)
Sys.time() - S
### Aggregate the data ###
vim_aggr <- aggregate(cbind(e_orig, VIM.T, LM.orig, LM.VIM, boost.orig,
boost.VIM, RF.orig, RF.VIM, GAM.orig, GAM.VIM) ~ ntrain + Var,
data = VIM.comp, mean, na.rm = TRUE)
vim_min <- aggregate(cbind(e_orig, LM.orig,  boost.orig,
RF.orig, GAM.orig) ~ ntrain,
data = VIM.comp, min, na.rm = TRUE)
# write.csv(VIM.comp, "small_test.csv", row.names = F)
#
# VIM.comp <- read.csv("small_test.csv")
vim_aggr <- aggregate(cbind(e_orig, VIM.T, LM.orig, LM.VIM, boost.orig,
boost.VIM, RF.orig, RF.VIM, GAM.orig, GAM.VIM) ~ ntrain + Var,
data = VIM.comp, mean, na.rm = TRUE)
View(VIM.comp)
