---
title: "Prof. Liu's code"
author: "Ismail Benchekroun"
date: "2022-09-01"
output: pdf
---

```{r, include = FALSE}
rm(list=ls())
# setwd("C:/Users/kuan liu/Dropbox (UT_KLiu)/thesis-simulation/paper1/")
library(mvtnorm)
library(nnet)
library(MCMCpack)
library(wgeesel)
library(lme4)
library(geepack)
library(MuMIn)
library(R2jags)
library(runjags)

options(warn=-1)

expit<-function(x){1/(1+exp(-x))}
logit<-function(p){log(p)-log(1-p)}
```

## Log-likelihood function
```{r, echo = FALSE}
loglik2<-function(param,resp1,resp2,resp3,mmat1,mmat2,mmat3,weight){
  
  n<-length(resp1)
  ### NOTE: param will have 5 entries, one for each theta and sigma
  theta <- param[1:3] ## 4 entries
  
  sigma11 <- param[4]  ## only 1 sigma because end of study outcome. would be 5th element
  # sigma22 <- param[5]
  # sigma33 <- param[6]
  # rho12 <- param[7] ### NOTE: this was for covariance modelling - don't need it
  # rho23 <- param[8]
  # rho13 <- param[9]
  
  # weight1<-as.vector(weight[,1]) 
  # weight2<-as.vector(weight[,2])
  weight3<-as.vector(weight[,3]) ## NOTE: only 1 weight
  
  e1<- (resp1 - mmat1%*%theta)
  
  logl <- NA

  if (sigma > 0){
    
    logl1<- -0.5*log(sigma11^2) - ((e1)^2)/(2*(sigma11^2)) ## ONly 1 log-likelihood, first one is good
    
    # sigma2<- sigma22^2 - (rho12^2)*(sigma22^2)
    # e2<- (resp2 - mmat2%*%theta) - rho12*sigma2/sigma11*e1
    # logl2<- -0.5*log(sigma2) - ((e2)^2)/(2*(sigma2))
    # 
    # sigma3<- (sigma33^2)*(1-rho12^2-rho23^2-rho13^2+2*rho12*rho23*rho13)/(1-rho12^2)
    # e3<- (resp3 - mmat3%*%theta) - e1*sigma33*(rho13-rho12*rho23)/sigma11/(1-rho12^2)-e2*sigma33*(rho23-rho12*rho13)/sigma22/(1-rho12^2)
    # logl3<- -0.5*log(sigma3) - ((e3)^2)/(2*(sigma3))
    # 
    logl<- sum(weight1*logl1)
    # +sum(weight2*logl2)+sum(weight3*logl3)
  }
  return(logl)
  
}

```

### JAGS model
```{r, echo = FALSE}
cat( " model {

     #N = nobs
     for (i in 1:N) {

     # conditional treatment assignment model;

     z1[i] ~ dbern(p1[i])
     logit(p1[i]) <- b10 + b11*x1[i] + b12*y1[i]

     z2[i] ~ dbern(p2[i])
     logit(p2[i]) <- b20 + b21*x2[i] + b22*y2[i] + b23*z1[i]

     # marginal treatment assignment model;

     z1s[i] ~ dbern(p1s[i])
     logit(p1s[i]) <- bs10

     z2s[i] ~ dbern(p2s[i])
     logit(p2s[i]) <- bs20 + bs21*z1[i]
     }

     # Priors
     b10 ~ dunif(-5,5) #true 0;
     b11 ~ dunif(-5,5) #true 0.2;
     b12 ~ dunif(-5,5) #true -0.05;

     b20 ~ dunif(-5,5)
     b21 ~ dunif(-5,5)
     b22 ~ dunif(-5,5)
     b23 ~ dunif(-5,5) #true 2

     bs10 ~ dunif(-5,5)
     bs20 ~ dunif(-5,5)
     bs21 ~ dunif(-5,5)

     }",
         file = "model_unif.txt")


```


### Simulation
```{r, echo = FALSE}
mysim <- function(outfile, from=1, to=1000, ntot=500, ncov=1, mean_x=0, mean_y=4, sigma_x = 1, sigma_y = 2, rho = -0.5,coeffz_x = 0.2, coeffz_y = -0.05, coeffz_z = 2, coeffy_z= 1, coeffx_z = -0.3, niter=20000, nburnin=10000, thin=10, nboot=2000) {
  
  i = 1;
  from=1; to=1; ntot=500; ncov=1; mean_x=1; mean_y=30; sigma_x = 1; sigma_y = 4;
  rho = -0.5;coeffz_x = 0.2; coeffz_y = -0.05; coeffz_z = 2;
  coeffy_z= 5; coeffx_z = -0.3; niter=15000; nburnin=5000; thin=5; nboot=2000
  
  samplesize <- (niter - nburnin)/thin
  results <- matrix(NA, to, 26)
  
  nL<-ncov + 1
  
  
  for (i in from:to) {
    iter <- 66500 + (i - 1)
    set.seed(iter)
    
    
    #Dec 15; 
    L <- array(NA, c(2, 2, ntot, 3 * nL)) 
    # calculating all potential x2,y2,x3,y3 based on z1 and z2
    #first dimention is 2 represent z1 = 0 and z1 = 1; 
    #second dim 2, represent z2 = 0 and z2 = 1; 
    #third dim ntot, represent number of subjects; 
    #last dim k*nL represent visits for x1, y1,x2, y2, x3,y3, in this order;
    Lobs <- matrix(NA, ntot, 3 * nL) #for k = 3, ncov = 1, first three columns rep x1,x2,x3 and last three col rep y1,y2,y3
    
    z <- matrix(NA, ntot, 3) #z1,z2,z3
    
    # x11 <- 
    #   x21 <-
    #   Y1 <-
    #   z1 <- x11, x21, y1
    # 
    # x12 (z1=0) <- x11, y1, z1
    # x12 (z1=1) <- x11, y1, z1
    # x12 (z1) <- x11, y1, z1
    # x22 (Z1=0) <- x21, y1, z1
    # x22 (Z1=1) <- x21, y1, z1
    # y2
    # z2
    
    
    # 1. visit 1:
    
    s <- matrix(c(sigma_x^2,(rho)*sigma_x*sigma_y,(rho)*sigma_x*sigma_y,sigma_y^2),2,2) #cov matrix of x1,y1
    Lobs[,1:nL] <- L[1,1,,1:nL] <- L[1,2,,1:nL] <- L[2,1,,1:nL] <- L[2,2,,1:nL]<- rmvnorm(ntot, c(mean_x, mean_y), s)
    m_z<- Lobs[,1] * coeffz_x + Lobs[,2] * coeffz_y ## 
    pz <- expit(m_z)
    z[,1] <- rbinom(ntot,1,prob=pz)
    
    
    # 2. visit 2:
    # s <- matrix(c(0.3^2,(rho)*0.3*3,(rho)*0.3*3,3^2),2,2)
    #for Z1 = 0;
    L[1,1,,(nL+1):(2*nL)] <- L[1,2,,(nL+1):(2*nL)] <- t(apply(L[1,1,,1:2], 1, function(x){rmvnorm(1, mean = x, s)}))
    
    #for z1 = 1;
    trt<- matrix(c(rep(coeffx_z,ntot), rep(coeffy_z,ntot)),ntot,2)
    L[2,1,,(nL+1):(2*nL)] <- L[2,2,,(nL+1):(2*nL)] <- t(apply( (L[2,1,,1:2] + trt), 1, function(x){rmvnorm(1, mean = x, s)}))
    
    for (j in (nL+1):(2*nL)) {
      Lobs[,j] <- L[cbind(z[,1]+1,1,1:ntot,j)]
    }
    
    m_z<- Lobs[,3] * coeffz_x + Lobs[,4] * coeffz_y + coeffz_z*z[,1]
    pz <- expit(m_z)
    z[,2] <- rbinom(ntot,1,prob=pz)
    
    
    # 3. intervention:
    #z1 = 0,z2 = 0
    L[1,1,,(2*nL+1):(3*nL)] <- t(apply(L[1,1,,3:4], 1, function(x){rmvnorm(1, mean = x, s)}))
    
    #z1 = 0,z2 = 1
    L[1,2,,(2*nL+1):(3*nL)] <- t(apply((L[1,2,,3:4]+trt), 1, function(x){rmvnorm(1, mean = x, s)}))
    
    #z1 = 1,z2 = 0
    L[2,1,,(2*nL+1):(3*nL)] <- t(apply(L[2,1,,3:4], 1, function(x){rmvnorm(1, mean = x, s)}))
    
    #z1 = 1,z2 = 1
    L[2,2,,(2*nL+1):(3*nL)] <- t(apply((L[2,2,,3:4]+trt), 1, function(x){rmvnorm(1, mean = x, s)}))
    
    for (j in (2*nL+1):(3*nL)) {
      Lobs[,j] <- L[cbind(z[,1]+1,z[,2]+1,1:ntot,j)]
    }
    
    m_z<- Lobs[,5] * coeffz_x + Lobs[,6] * coeffz_y + coeffz_z*z[,2]
    pz <- expit(m_z)
    z[,3] <- rbinom(ntot,1,prob=pz)
    
    #creating observed wide datasets;
    obs<-data.frame(Lobs,z,rep(0,ntot), z[,1], rowSums(z[,1:2]),rep(1,ntot),rep(2,ntot),rep(3,ntot))
    colnames(obs)<-c("x1", "y1","x2", "y2","x3", "y3","z1", "z2","z3","cumz1","cumz2","cumz3", "visit1","visit2","visit3")
    obs$id<-seq(1, ntot, by=1)
    #Creating observed long datasets to model weighted GEE;
    lobs<-rbind( cbind(seq(1, ntot, by=1),Lobs[,1:nL],z[,1]),cbind(seq(1, ntot, by=1), Lobs[,(nL+1):(2*nL)],z[,2]),cbind(seq(1, ntot, by=1), Lobs[,(2*nL+1):(3*nL)],z[,3]))
    time<-c(rep(1, ntot), rep(2, ntot), rep(3,ntot))
    lcumz<-c(rep(0,ntot), z[,1], rowSums(z[,1:2]))
    obslong<-data.frame(lobs, time, lcumz)
    colnames(obslong)<-c("id", "x","y", "z","time", "lcumz")
    # head(obslong)
    # dim(obslong) #1500 rows, 6 cols
    obslong <- obslong[order(obslong$id),] 
    
    #coding true effect by generating potential outcomes longdataset;
    lobs_t1<-cbind(seq(1, ntot, by=1),L[1,1,,1:nL], rep(0,ntot), rep(1,ntot)) #lcumz = 0;
    lobs_t2_1<-cbind(seq(1,ntot,by = 1), L[1,1,,(nL+1):(2*nL)], rep(0,ntot), rep(2, ntot)) #z1=0, lcumz=0;
    lobs_t2_2<-cbind(seq(1,ntot,by = 1), L[2,1,,(nL+1):(2*nL)], rep(1,ntot), rep(2, ntot)) #z1=1, lcumz = 1;
    lobs_t3_1<-cbind(seq(1,ntot,by = 1), L[1,1,,(2*nL+1):(3*nL)], rep(0,ntot), rep(3, ntot)) #z1=0, z2 = 0, lcumz=0;
    lobs_t3_2<-cbind(seq(1,ntot,by = 1), L[1,2,,(2*nL+1):(3*nL)], rep(1,ntot), rep(3, ntot)) #z1=0, z2 = 1, lcumz = 1;
    lobs_t3_3<-cbind(seq(1,ntot,by = 1), L[2,1,,(2*nL+1):(3*nL)], rep(1,ntot), rep(3, ntot)) #z1=1, z2 = 0, lcumz = 1;
    lobs_t3_4<-cbind(seq(1,ntot,by = 1), L[2,2,,(2*nL+1):(3*nL)], rep(2,ntot), rep(3, ntot)) #z1=1, z2 = 1, lcumz=2;
    truelong<-data.frame(rbind(lobs_t1,lobs_t2_1, lobs_t2_2, lobs_t3_1, lobs_t3_2, lobs_t3_3, lobs_t3_4))
    colnames(truelong)<-c("id", "x","y", "lcumz", "time")
    head(truelong)
    dim(truelong) #3500 rows,    5 cols
    truelong <- truelong[order(truelong$id),]

    trueGEE<-geese(truelong$y~truelong$lcumz+truelong$time, id = truelong$id, data = truelong, family = gaussian, corstr = "ar1")
    summary(trueGEE) #5.224   0.388  181.70
    results[i,1] <- coef(trueGEE)[2]
    results[i,2] <- trueGEE$vbeta[2,2]
    
    # E(y11) - E(y00) this is saying E(Y01) is not the same as E(Y10)
    # lm(Y_endofstudy ~ cumz), cumz will be a ordinal variable 0,1,2
    
    # trueGEE2<-geese(truelong$y~truelong$lcumz+truelong$time, id = truelong$id, data = truelong, family = gaussian,corstr = "independence")
    # # summary(trueGEE2)
    # results[i,3] <- coef(trueGEE2)[2]
    # results[i,4] <- trueGEE2$vbeta[2,2]
    
    
    #unweighted GEE biased - naive approach;
    # "independence", "exchangeable", "ar1","unstructured" and "userdefined";
    simpleGEE2<-geese(obslong$y~obslong$lcumz+obslong$time, id = obslong$id, data = obslong, family = gaussian, corstr = "ar1")
    # summary(simpleGEE)
    results[i,1] <- coef(simpleGEE2)[2]
    results[i,2] <- simpleGEE2$vbeta[2,2]
    
    
    #calculating wegiths
    #unstable weights
    # IPT weights:
    
    tmodel1 <- glm(z1 ~ x1 + y1, family=binomial(link=logit), data = obs)
    tmodel2 <- glm(z2 ~ x2 + y2 + z1, family=binomial(link=logit), data = obs)
    
    tlp1 <- as.matrix(cbind(1.0, obs[,1:2])) %*% as.matrix(coef(tmodel1))
    tlp2 <- as.matrix(cbind(1.0, obs[,3:4], z[,1])) %*% as.matrix(coef(tmodel2))
    
    smodel1 <- glm(z1 ~ 1, family=binomial(link=logit), data = obs)
    smodel2 <- glm(z2 ~ z1, family=binomial(link=logit), data = obs)
    
    slp1 <- as.matrix(cbind(rep(1.0, ntot))) %*% as.matrix(coef(smodel1))
    slp2 <- as.matrix(cbind(1.0, z[,1])) %*% as.matrix(coef(smodel2))
    
    pt <- (exp(z[,1] * tlp1)/(1+exp(tlp1))) * (exp(z[,2] * tlp2)/(1+exp(tlp2)))
    
    sc <- (exp(z[,1] * slp1)/(1+exp(slp1))) * (exp(z[,2] * slp2)/(1+exp(slp2)))      
    
    iptw1 <- 1.0/(exp(z[,1] * tlp1)/(1+exp(tlp1)))
    iptws1 <- (exp(z[,1] * slp1)/(1+exp(slp1))) * iptw1
    
    iptw2 <- 1.0/pt
    iptws2 <- sc * iptw2
    
    iptw<-c(rep(1,ntot),as.vector(iptw1), as.vector(iptw2))
    iptws<-c(rep(1,ntot),as.vector(iptws1), as.vector(iptws2))
    myweight<-data.frame(rep(seq(1,ntot,1),3), time, iptw, iptws)
    myweight<-myweight[order(myweight[1]),] 
    obslong<-data.frame(obslong,myweight[,3:4])
    
    
    # Unstabilized weights: sandwich variance;:
    wGEE_unstable2<-geese(obslong$y~obslong$lcumz+obslong$time, id = obslong$id, data = obslong, weights = iptw ,family = gaussian, corstr = "independence")
    results[i,3] <- coef(wGEE_unstable2)[2]
    results[i,4] <- wGEE_unstable2$vbeta[2,2]
    
    wGEE_stable2<-geese(obslong$y~obslong$lcumz+obslong$time, id = obslong$id, data = obslong, weights = iptws ,family = gaussian, corstr = "independence")
    results[i,5] <- coef(wGEE_stable2)[2]
    results[i,6] <- wGEE_stable2$vbeta[2,2]
    
    # Bayesian inference 1. BMSM
    # first obtain MCMC sample for weights! from posterier distribution of treatment assignment parameters;
    jags.data<-list(x1= obs$x1, y1=obs$y1, z1=obs$z1,  x2=obs$x2, y2=obs$y2, z2=obs$z2, z1s = obs$z1 , z2s=obs$z2, N = ntot)
    jags.params<-c("b10","b11","b12","b20","b21", "b22","b23",
                   "bs10","bs20","bs21")
    
    jags.inits<-function(){list(b10=coef(tmodel1)[1],
                                b11=coef(tmodel1)[2],
                                b12=coef(tmodel1)[3],
                                b20=coef(tmodel2)[1],
                                b21=coef(tmodel2)[2],
                                b22=coef(tmodel2)[3],
                                b23 = coef(tmodel2)[4],
                                bs10 = coef(smodel1),
                                bs20 = coef(smodel2)[1],
                                bs21 = coef(smodel2)[2])}
    
    jagsfit<- jags(data = list(x1= obs$x1, y1=obs$y1, z1=obs$z1,  x2=obs$x2, y2=obs$y2, z2=obs$z2, z1s = obs$z1 , z2s=obs$z2, N = ntot), inits = jags.inits, jags.params, n.iter = niter, 
                   model.file = "model_unif.txt", n.chains = 1, n.burnin = nburnin, n.thin = thin)     ## not uniform, because restrictive - use normal (eg normal(0, 5)) and specify variance such that majority of samples are between restricted zone
    
    # or to use some plots in coda
    # use as.mcmmc to convert rjags object into mcmc.list
    jags.mcmc <- as.mcmc(jagsfit)
    out.mcmc <- as.matrix(jags.mcmc[[1]])
    
    obs_prob1<-matrix(NA, samplesize, ntot)
    exp_prob1<-matrix(NA, samplesize, ntot)
    obs_prob2<-matrix(NA, samplesize, ntot)
    exp_prob2<-matrix(NA, samplesize, ntot)
    
    mcmcweight_w<-array(NA, dim = c(ntot,3,samplesize))
    mcmcweight_ws<-array(NA, dim = c(ntot,3,samplesize))
    
    #calulating the MCMC weights;
    for (i2 in 1:(samplesize)){
      for (j2 in 1:(ntot)){
        
        exp_prob1[i2,j2] <- (exp(z[j2,1]*out.mcmc[i2,8]))/(1.0+exp(out.mcmc[i2,8])) ## for each person, there should be 20000 posterior treatment probabilities.
        exp_prob2[i2,j2] <- exp_prob1[i2,j2]*(exp(z[j2,2]*(out.mcmc[i2,9]+out.mcmc[i2,10]*z[j2,1])))/(1.0+exp(out.mcmc[i2,9]+out.mcmc[i2,10]*z[j2,1]))
        
        obs_prob1[i2,j2] <- (exp(z[j2,1]*(out.mcmc[i2,1] + out.mcmc[i2,2]*Lobs[j2,1]+out.mcmc[i2,3]*Lobs[j2,2])))/(1.0+exp(out.mcmc[i2,1] + out.mcmc[i2,2]*Lobs[j2,1]+out.mcmc[i2,3]*Lobs[j2,2]))
        obs_prob2[i2,j2] <- obs_prob1[i2,j2]*(exp(z[j2,2]*(out.mcmc[i2,4]+out.mcmc[i2,5]*Lobs[j2,3]+out.mcmc[i2,6]*Lobs[j2,4]+out.mcmc[i2,7]*z[j2,1])))/(1.0+exp(out.mcmc[i2,4]+out.mcmc[i2,5]*Lobs[j2,3]+out.mcmc[i2,6]*Lobs[j2,4]+out.mcmc[i2,7]*z[j2,1]))
        
        mcmcweight_w[j2, ,i2]<-c(1, 1/obs_prob1[i2,j2], 1.0/obs_prob2[i2,j2])
        mcmcweight_ws[j2, ,i2]<-c(1, exp_prob1[i2,j2]/obs_prob1[i2,j2], exp_prob2[i2,j2]/obs_prob2[i2,j2]) ## for each iteration, we have a stabilized weight for person j2. 
      }
      
      # if (i2 %% 50 == 0) {
      #   print(i2)
      # }
    }
    
    
    #1. Two Step Bayesian with mcmcweights in step one and likelihood approach in step 2;
    #looping throung all MCMC weights and adjust them in GEE;
    # 
    # pointest_w2 <-numeric(samplesize)
    # pointest_ws2<-numeric(samplesize)
    # varestsand_w2 <-numeric(samplesize)
    # varestsand_ws2<-numeric(samplesize)
    # 
    # 
    # for (j7 in 1:samplesize) {
    #   
    #   w<- as.vector(t(mcmcweight_w[,,j7]))
    #   ws<- as.vector(t(mcmcweight_ws[,,j7]))
    #   
    #   wGEE_bayes_n2<-geese(obslong$y~obslong$lcumz+obslong$time, id = obslong$id, data = obslong, weights = w ,family = gaussian, corstr = "independence")
    #   pointest_w2[j7] <- coef(wGEE_bayes_n2)[2]
    #   varestsand_w2[j7] <-wGEE_bayes_n2$vbeta[2,2]
    #   
    #   wGEE_bayes_s2<-geese(obslong$y~obslong$lcumz+obslong$time, id = obslong$id, data = obslong, weights = ws ,family = gaussian,corstr = "independence")
    #   pointest_ws2[j7] <- coef(wGEE_bayes_s2)[2]
    #   varestsand_ws2[j7] <-wGEE_bayes_s2$vbeta[2,2]
    #   
    # }
    # 
    # results[i,7] <- mean(pointest_w2)
    # results[i,8] <- mean(varestsand_w2) + var(pointest_w2)
    # results[i,9] <- var(pointest_w2)
    # results[i,10] <- mean(varestsand_w2)
    # 
    # results[i,11] <- mean(pointest_ws2)
    # results[i,12] <- mean(varestsand_ws2) + var(pointest_ws2)
    # results[i,13] <- var(pointest_ws2)
    # results[i,14] <- mean(varestsand_ws2)
    
    #2. Getting Mean MCMC weight! This does not account for weight estimation uncertainty, should not really be included;
    # obs_prob1m<-numeric(ntot)
    # obs_prob2m<-numeric(ntot)
    # exp_prob1m<-numeric(ntot)
    # exp_prob2m<-numeric(ntot)
    # mcmcweight_wm<-matrix(NA, ntot,3)
    # mcmcweight_wsm<-matrix(NA, ntot,3)
    # 
    # for (j3 in 1:(ntot)){
    #   
    #   exp_prob1m[j3] <- (exp(z[j3,1]*mean(out.mcmc[,8])))/(1.0+exp(mean(out.mcmc[,8])))
    #   exp_prob2m[j3] <- exp_prob1m[j3]*(exp(z[j3,2]*(mean(out.mcmc[,9])+mean(out.mcmc[,10])*z[j3,1])))/(1.0+exp(mean(out.mcmc[,9])+mean(out.mcmc[,10])*z[j3,1]))
    #   
    #   obs_prob1m[j3] <- (exp(z[j3,1]*(mean(out.mcmc[,1]) + mean(out.mcmc[,2])*Lobs[j3,1]+mean(out.mcmc[,3])*Lobs[j3,2])))/(1.0+exp(mean(out.mcmc[,1]) + mean(out.mcmc[,2])*Lobs[j3,1]+mean(out.mcmc[,3])*Lobs[j3,2]))
    #   obs_prob2m[j3] <- obs_prob1m[j3]*(exp(z[j3,2]*(mean(out.mcmc[,4])+mean(out.mcmc[,5])*Lobs[j3,3]+mean(out.mcmc[,6])*Lobs[j3,4]+mean(out.mcmc[,7])*z[j3,1])))/(1.0+exp(mean(out.mcmc[,4])+mean(out.mcmc[,5])*Lobs[j3,3]+mean(out.mcmc[,6])*Lobs[j3,4]+mean(out.mcmc[,7])*z[j3,1]))
    #   
    #   mcmcweight_wm[j3, ]<-c(1, 1/obs_prob1m[j3], 1.0/obs_prob2m[j3])
    #   mcmcweight_wsm[j3,]<-c(1, exp_prob1m[j3]/obs_prob1m[j3], exp_prob2m[j3]/obs_prob2m[j3])
    # }
    # 
    # wm<- as.vector(t(mcmcweight_wm))
    # wsm<- as.vector(t(mcmcweight_wsm))
    # 
    # wGEE_bayes_wmean2<-geese(obslong$y~obslong$lcumz+obslong$time, id = obslong$id, data = obslong, weights = as.vector(wm) ,family = gaussian, corstr = "independence")
    # results[i,15] <- coef(wGEE_bayes_wmean2)[2]
    # results[i,16] <- wGEE_bayes_wmean2$vbeta[2,2]
    # 
    # wGEE_bayes_wmean4<-geese(obslong$y~obslong$lcumz+obslong$time, id = obslong$id, data = obslong, weights = as.vector(wsm) ,family = gaussian, corstr = "independence")
    # results[i,17] <- coef(wGEE_bayes_wmean4)[2]
    # results[i,18] <- wGEE_bayes_wmean4$vbeta[2,2]
    
    wmean2_s <- colSums(exp_prob1)/colSums(obs_prob1) ## = colSums(exp_prob1 / obs_prob1) only taking mean 
    wmean3_s <- colSums(exp_prob2)/colSums(obs_prob2)
    wmean_s<-cbind(rep(1,ntot),wmean2_s, wmean3_s)
    
    ### NOTE: in end-of-study outcome, only have one wmean_3 (as opposed to for visit 2 + 3)
    
    #Multinomial sampling - unweighted error variance:
  
    # inits2<-c(30,5,0.2,4,6,8,0.7,0.8,0.6) 
    
    # bootest1<-numeric(nboot)
    # 
    # for (j6 in 1:nboot) {
    #   alpha <- rep(1/ntot, ntot)
    #   bootidx <- as.matrix(rep(1:ntot, rmultinom(1, ntot, alpha)))
    #   
    #   maxim <- optim(inits2, fn=loglik2,resp1=obs$y1[bootidx], resp2=obs$y2[bootidx],resp3=obs$y3[bootidx], mmat1=cbind(1,obs$cumz1[bootidx],1), mmat2=cbind(1,obs$cumz2[bootidx],2),mmat3=cbind(1,obs$cumz3[bootidx],3),weight=wmean_s[bootidx,],
    #                  control=list(fnscale=-1), method='BFGS', hessian=F)
    #   bootest1[j6] <- maxim$par[2]
    #   
    #   # if (j6 %% 50 == 0) {
    #   #   print(j6)
    #   # }
    # }
    # 
    # results[i,19] <- mean(bootest1)
    # results[i,20] <- var(bootest1)
    # results[i,21:22] <- quantile(bootest1, probs=c(0.025,0.975))
    
    # inits3<-c(30,5,0.2) 
    # bootest1<-numeric(nboot)
    # 
    # for (j6 in 1:nboot) {
    #   alpha <- rep(1/ntot, ntot)
    #   bootidx <- as.matrix(rep(1:ntot, rmultinom(1, ntot, alpha)))
    #   
    #   maxim <- optim(inits3, fn=sqrfunc,resp1=obs$y1[bootidx], resp2=obs$y2[bootidx],resp3=obs$y3[bootidx], mmat1=cbind(1,obs$cumz1[bootidx],1), mmat2=cbind(1,obs$cumz2[bootidx],2),mmat3=cbind(1,obs$cumz3[bootidx],3),weight=wmean_s[bootidx,],
    #                  control=list(fnscale=-1), method='BFGS', hessian=F)
    #   bootest1[j6] <- maxim$par[2]
    #   
    #   # if (j6 %% 50 == 0) {
    #   #   print(j6)
    #   # }
    # }
    # 
    # results[i,19] <- mean(bootest1)
    # results[i,20] <- var(bootest1)
    # results[i,21:22] <- quantile(bootest1, probs=c(0.025,0.975))
    
   ### NOTE: use this method below instead of sqrfcn. L 
    # Dirichlet sampling - unweighted error:
    bootest3<-numeric(nboot)

    for (j8 in 1:nboot) {
      alpha <- as.numeric(rdirichlet(1, rep(1.0, ntot)))
      ## y_end ~ normal distribution with mean and sigma_squared. Mean is modelled by theta0+theta1*z1+theta2*z2 (if there's interaction, then add theta3*z1*z2). sigma has to be > 0. 0 for theta's and 1 for sigma as initial points. need design matrix
      maxim <- optim(inits2, fn=loglik2,resp1=obs$y1, resp2=obs$y2,resp3=obs$y3, mmat1=cbind(1, obs$z1, obs$z2, obsz1 * obs$z2), 
                     # mmat2=cbind(1,obs$cumz2,2),mmat3=cbind(1,obs$cumz3,3),
                     weight=alpha*wmean_s,
                     control=list(fnscale=-1), method='BFGS', hessian=F)
      bootest3[j8] <- maxim$par[2]

      if (j8 %% 50 == 0) {
        print(j8)
      }
    }
## Survey package

    results[i,23] <- mean(bootest3)
    results[i,24] <- var(bootest3)
    results[i,25:26] <- quantile(bootest3, probs=c(0.025,0.975))

    # bootest3<-numeric(nboot)
    # 
    # for (j8 in 1:nboot) {
    #   alpha <- as.numeric(rdirichlet(1, rep(1.0, ntot)))
    #   
    #   maxim <- optim(inits3, fn=sqrfunc,resp1=obs$y1, resp2=obs$y2,resp3=obs$y3, mmat1=cbind(1,obs$cumz1,1), mmat2=cbind(1,obs$cumz2,2),mmat3=cbind(1,obs$cumz3,3),weight=alpha*wmean_s,
    #                  control=list(fnscale=-1), method='BFGS', hessian=F)
    #   bootest3[j8] <- maxim$par[2]
    #   
    #   # if (j8 %% 50 == 0) {
    #   #   print(j8)
    #   # }
    # }
    
    
    results[i,23] <- mean(bootest3)
    results[i,24] <- var(bootest3)
    results[i,25:26] <- quantile(bootest3, probs=c(0.025,0.975))
    
    if (i%% 1==0){print(i)}
    # print(results)
  }
  
  write.table(cbind(from:to,results), outfile, row.names = FALSE,col.names = FALSE)
  
}

```



mysim("mysim100_may02_test.txt", from = 1, to = 100, ntot = 500, ncov = 1, mean_x=1, mean_y=30, sigma_x = 1, sigma_y = 4, rho = -0.5, coeffz_x = 0.2, coeffz_y = -0.05, coeffz_z = 2, coeffy_z = 5, coeffx_z = -0.3, niter=15000, nburnin=5000, thin=5, nboot=2000)